{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Glider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dustin D. Gerrard\n",
    "### July 15, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glider import Glider\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Neural Fitted Q Iteration: http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf\n",
    "\n",
    "# STATES \n",
    "# (x, y, x_dot, y_dot, phi)\n",
    "\n",
    "# DISCRETE ACTIONS\n",
    "ACTIONS = (-1.0, 0.0, 1.0)\n",
    "\n",
    "# TARGET (X)\n",
    "target_x = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_epsilon(epsilon_init, epsilon_min, episode_step, num_steps_epsilon_decay):\n",
    "    epsilon = epsilon_init*np.power(0.9,(episode_step/num_steps_epsilon_decay))\n",
    "    if epsilon < epsilon_min:\n",
    "        epsilon = epsilon_min\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_trajectory(episode_list):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(episode_list)):\n",
    "        state = episode_list[i][0]\n",
    "        X.append(state[0])\n",
    "        Y.append(state[2])\n",
    "    plt.plot(X,Y)\n",
    "    plt.scatter(125.0,0)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_data(episode_list, total_cost, w_effort):\n",
    "    X_NN = []\n",
    "    Y_NN = []\n",
    "    Q = total_cost\n",
    "    for i in range(len(episode_list)):        \n",
    "        X_NN.append(episode_list[i][0][0:5])\n",
    "        Y_NN.append(Q)\n",
    "        Q -= episode_list[i][2]*w_effort\n",
    "    return X_NN, Y_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_input = 5\n",
    "num_l1 = 10\n",
    "num_l2 = 10\n",
    "num_out = 1\n",
    "W = {\n",
    "    'h1':tf.Variable(tf.random_normal([num_input,num_l1])),\n",
    "    'h2':tf.Variable(tf.random_normal([num_l1, num_l2])),\n",
    "    'out':tf.Variable(tf.random_normal([num_l2, num_out]))\n",
    "}    \n",
    "b = {\n",
    "    'b1':tf.Variable(tf.random_normal([num_l1])),\n",
    "    'b2':tf.Variable(tf.random_normal([num_l2])),\n",
    "    'out':tf.Variable(tf.random_normal([num_out]))\n",
    "}\n",
    "\n",
    "def multilayer_perceptron(x, W, b):        \n",
    "    l1 = tf.add(tf.matmul(x, W['h1']), b['b1'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l2 = tf.add(tf.matmul(l1, W['h2']), b['b2'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    out = tf.add(tf.matmul(l2, W['out']), b['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main learning loop\n",
    "## policy_matrix = np.random.randint(low = 0, high = NUM_ACTIONS, size = NUM_BUCKETS)\n",
    "## state_action_matrix = np.zeros((NUM_ACTIONS, num_buckets))\n",
    "\n",
    "# epsilon greedy determines which action to take during training.\n",
    "\n",
    "w_effort = 1.0\n",
    "w_target = 6.0\n",
    "num_episodes = 10 # 10\n",
    "max_step = 1000 # 10k\n",
    "env = Glider()\n",
    "for episode in range(num_episodes):\n",
    "    if episode%10 == 0:\n",
    "        print('Episode: ' + str(episode))\n",
    "    epsilon = get_epsilon(0.99, 0.1, episode, 10)\n",
    "    Y, X, V = [], [], []\n",
    "    episode_list = list()\n",
    "    total_cost = 0.0\n",
    "    state = env.reset()\n",
    "    # state_disc = get_discrete_states(state_cont, all_state_arrays)\n",
    "    effort_cost = 0.0\n",
    "    for step in range(max_step):\n",
    "        action = random.choice(ACTIONS)\n",
    "        cost, done = env.step(action)\n",
    "        new_state = env.get_state()\n",
    "        total_cost += cost\n",
    "        episode_list.append((state, action, cost))                \n",
    "        state = new_state\n",
    "        if done:\n",
    "            break\n",
    "        effort_cost += cost\n",
    "    glider_landing_x = episode_list[len(episode_list)-1][0][0]\n",
    "    target_cost = abs(target_x - glider_landing_x)\n",
    "    total_cost = w_target*target_cost + w_effort*effort_cost\n",
    "    \n",
    "    # plot trajectory\n",
    "    plot_trajectory(episode_list)\n",
    "    plt.hold\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effort_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cost*w_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_landing = episode_list[len(episode_list)-1][0]\n",
    "print(state_landing)\n",
    "landing_velocity = math.sqrt(state_landing[1]**2 + state_landing[3]**2)\n",
    "landing_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NFQ main learning loop\n",
    "## policy_matrix = np.random.randint(low = 0, high = NUM_ACTIONS, size = NUM_BUCKETS)\n",
    "## state_action_matrix = np.zeros((NUM_ACTIONS, num_buckets))\n",
    "\n",
    "# epsilon greedy determines which action to take during training.\n",
    "\n",
    "# neural net\n",
    "sess = tf.Session()\n",
    "Q_net = multilayer_perceptron(tf.placeholder(\"float\", [None,5]), W, b)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "labels = [[[1]]]\n",
    "predictions = [a]\n",
    "loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "w_effort = 1.0\n",
    "w_target = 6.0\n",
    "num_episodes = 10 # 10\n",
    "max_step = 1000 # 10k\n",
    "env = Glider()\n",
    "for episode in range(num_episodes):\n",
    "    if episode%10 == 0:\n",
    "        print('Episode: ' + str(episode))\n",
    "    epsilon = get_epsilon(0.99, 0.1, episode, 10)\n",
    "    Y, X, V = [], [], []\n",
    "    episode_list = list()\n",
    "    total_cost = 0.0\n",
    "    state = env.reset()\n",
    "    # state_disc = get_discrete_states(state_cont, all_state_arrays)\n",
    "    effort_cost = 0.0\n",
    "    for step in range(max_step):\n",
    "        state_action_1 = env.probe_step(1.0)\n",
    "        state_action_0 = env.probe_step(0.0)\n",
    "        state_action_minus_1 = env.probe_step(-1.0)\n",
    "        Q_1 = sess.run(Q_net, {x : [state_action_1,]})\n",
    "        Q_0 = sess.run(Q_net, {x : [state_action_0,]})\n",
    "        Q_m1 = sess.run(Q_net, {x : [state_action_minus_1,]})\n",
    "        print(Q_1)\n",
    "        print(Q_0)\n",
    "        print(Q_m1)\n",
    "        action = random.choice(ACTIONS)\n",
    "        cost, done = env.step(action)\n",
    "        new_state = env.get_state()\n",
    "        total_cost += cost\n",
    "        episode_list.append((state, action, cost))                \n",
    "        state = new_state\n",
    "        if done:\n",
    "            break\n",
    "        effort_cost += cost\n",
    "    \n",
    "    glider_landing_x = episode_list[len(episode_list)-1][0][0]\n",
    "    target_cost = abs(target_x - glider_landing_x)\n",
    "    total_cost = w_target*target_cost + w_effort*effort_cost\n",
    "    \n",
    "    # train MLP           \n",
    "    A, B = training_data(episode_list, total_cost, w_effort)\n",
    "    A = tf.Variable(A)\n",
    "    labels = np.transpose([B])\n",
    "    predictions = multilayer_perceptron(A)\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    train_step = tf.train.GradientDescentOptimizer(1e-8).minimize(loss)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(loss))\n",
    "    sess.run(train_step)\n",
    "    print(sess.run(loss))\n",
    "    \n",
    "    # plot trajectory\n",
    "    plot_trajectory(episode_list)\n",
    "    plt.hold\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_action_1)\n",
    "print(state_action_0)\n",
    "print(state_action_minus_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_1 = sess.run(Q_net, {x : [[1,2,3,4,5],]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(prediction_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple inputs/outputs\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "A, B = training_data(episode_list, total_cost, w_effort)\n",
    "\n",
    "sess = tf.Session()\n",
    "x = tf.Variable(A)\n",
    "a = multilayer_perceptron(x)\n",
    "print(a)\n",
    "labels = np.transpose([B])\n",
    "predictions = multilayer_perceptron(x)\n",
    "loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-8).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "# a = multilayer_perceptron(x)\n",
    "# print(sess.run(a))\n",
    "print(sess.run(loss))\n",
    "sess.run(train_step)\n",
    "# print(sess.run(a))\n",
    "print(sess.run(loss))\n",
    "\n",
    "for i in range(100000):\n",
    "    sess.run(train_step)\n",
    "    # print(sess.run(a))\n",
    "    if i%1000 == 0:\n",
    "        print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = training_data(episode_list, total_cost, w_effort)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_NN0 = training_data(episode_list, total_cost, w_effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list[len(episode_list)-2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(episode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(episode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = random.choice(ACTIONS)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " X, Y, A = [], [], [],\n",
    "for i in range(len(episode_list)):\n",
    "    state = episode_list[i][0]\n",
    "    X.append(state[0])\n",
    "    Y.append(state[2])\n",
    "    A.append(episode_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1.0)\n",
    "env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([[0.0,1.0,2.0,3.0,4.0],])\n",
    "# multilayer_perceptron(x)\n",
    "num_input = 5 \n",
    "num_l1 = 2\n",
    "W = {'h1':tf.Variable(tf.random_normal([num_input,num_l1]))}\n",
    "a = tf.matmul(x, W['h1'])\n",
    "# W['h1']\n",
    "sess = tf.Session()\n",
    "print(W['h1'])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(W['h1']))\n",
    "print(sess.run(x))\n",
    "print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([[0.0,1.0,2.0,3.0,4.0],])\n",
    "a = multilayer_perceptron(x)\n",
    "print(a)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_47:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\Dustin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[None, 103.09693]\n",
      "[None, 11.722347]\n",
      "[None, 1.5383936]\n",
      "[None, 0.15390986]\n",
      "[None, 0.014678886]\n",
      "[None, 0.0013974456]\n",
      "[None, 0.00013286489]\n",
      "[None, 1.2633786e-05]\n",
      "[None, 1.1973219e-06]\n",
      "[None, 1.1201075e-07]\n",
      "[None, 1.055929e-08]\n",
      "[None, 9.2768815e-10]\n",
      "[None, 5.287859e-11]\n",
      "[None, 6.9633188e-13]\n",
      "[None, 6.9633188e-13]\n",
      "[None, 6.9633188e-13]\n",
      "[None, 6.9633188e-13]\n",
      "[None, 6.9633188e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n",
      "[None, 1.2789769e-13]\n"
     ]
    }
   ],
   "source": [
    "# Working neural net\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "num_input = 5\n",
    "num_l1 = 10\n",
    "num_l2 = 10\n",
    "num_out = 1\n",
    "W = {\n",
    "    'h1':tf.Variable(tf.random_normal([num_input,num_l1])),\n",
    "    'h2':tf.Variable(tf.random_normal([num_l1, num_l2])),\n",
    "    'out':tf.Variable(tf.random_normal([num_l2, num_out]))\n",
    "}    \n",
    "b = {\n",
    "    'b1':tf.Variable(tf.random_normal([num_l1])),\n",
    "    'b2':tf.Variable(tf.random_normal([num_l2])),\n",
    "    'out':tf.Variable(tf.random_normal([num_out]))\n",
    "}\n",
    "\n",
    "def multilayer_perceptron(x, W, b):        \n",
    "    l1 = tf.add(tf.matmul(x, W['h1']), b['b1'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l2 = tf.add(tf.matmul(l1, W['h2']), b['b2'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    out = tf.add(tf.matmul(l2, W['out']), b['out'])\n",
    "    return out\n",
    "\n",
    "sess = tf.Session()\n",
    "# x = tf.Variable([[0.0,1.0,2.0,3.0,4.0],])\n",
    "x = tf.placeholder(\"float\", [None,num_input])\n",
    "y_ = multilayer_perceptron(x, W, b)\n",
    "print(a)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, 1]) #, name = 'y')   # 3 outputs\n",
    "labels = y\n",
    "predictions = a\n",
    "loss = tf.losses.mean_squared_error(y, y_)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "# a = multilayer_perceptron(x)\n",
    "# print(sess.run(a))\n",
    "print(sess.run([train_step, loss], feed_dict={x:[[1,2,3,4,5],[2,3,4,5,6]], y:[[1],[2]]}))\n",
    "# print(sess.run(loss))\n",
    "# sess.run(train_step)\n",
    "# print(sess.run(a))\n",
    "# print(sess.run(loss))\n",
    "\n",
    "for i in range(100):\n",
    "    print(sess.run([train_step, loss], feed_dict={x:[[1,2,3,4,5],], y:[[1]]}))\n",
    "    # print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16691241,  0.59427404,  2.37687016,  2.3382268 ,  3.4388082 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = sess.run(a , {x : [[0.0,1.0,2.0,3.0,4.0],]})\n",
    "model_result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    " \n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with ReLU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with ReLU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    " \n",
    "# Store layers weight &amp; bias\n",
    "weights = {\n",
    "'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    " \n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
